{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hvl2UnDdnxxS"
      },
      "outputs": [],
      "source": [
        "# !mkdir -p ~/.kaggle\n",
        "# !cp kaggle.json ~/.kaggle/\n",
        "# !chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QOhiWXiTn8Do"
      },
      "outputs": [],
      "source": [
        "# !kaggle datasets download borhanitrash/alzheimer-mri-disease-classification-dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AA747Eqyn_r7"
      },
      "outputs": [],
      "source": [
        "# import zipfile\n",
        "\n",
        "# zip_ref=zipfile.ZipFile('/content/Dataset.zip','r')\n",
        "# zip_ref.extractall('/Dataset.zip')\n",
        "# zip_ref.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rTX1OM8Soxdt"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hnHA2PEMoCUe"
      },
      "outputs": [],
      "source": [
        "!pip install keras\n",
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S1Vf0ee-oEfR"
      },
      "outputs": [],
      "source": [
        "#Set up the environment and upload the data\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from  glob import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import matplotlib.image as mpimg\n",
        "from skimage.transform import resize\n",
        "import pandas as pd\n",
        "from matplotlib.image import imread\n",
        "from skimage.io import imread_collection\n",
        "from PIL import Image\n",
        "import seaborn as sns\n",
        "from sklearn import decomposition, preprocessing, svm\n",
        "import sklearn.metrics as metrics #confusion_matrix, accuracy_score\n",
        "from time import sleep\n",
        "from tqdm.notebook import tqdm\n",
        "import os\n",
        "sns.set()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy==1.26.4 --force-reinstall\n"
      ],
      "metadata": {
        "id": "oungXXwk7sjB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.kill(os.getpid(), 9)\n",
        "\n"
      ],
      "metadata": {
        "id": "0oCG45ov71MK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "print(np.__version__)  # should print 1.26.4\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kd7kR9LZ8hVH",
        "outputId": "2847727a-fbb7-4121-c5d9-1a874e23ad4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.26.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "oOqQS29j6lqo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XxOkmNbVISPW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e0a5b20-16b9-4a6c-85a1-9252a7606775"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ ZIP is valid. Found 12812 files.\n",
            "First 5 files:\n",
            "['Dataset/', '__MACOSX/._Dataset', 'Dataset/.DS_Store', '__MACOSX/Dataset/._.DS_Store', 'Dataset/Moderate_Demented/']\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "\n",
        "zip_path = '/content/Dataset.zip'\n",
        "\n",
        "try:\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        file_list = zip_ref.namelist()\n",
        "        print(f\"✅ ZIP is valid. Found {len(file_list)} files.\")\n",
        "        print(\"First 5 files:\")\n",
        "        print(file_list[:5])\n",
        "except zipfile.BadZipFile:\n",
        "    print(\"❌ BadZipFile: This is not a valid ZIP file. Re-upload or re-download it.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6sW_bh9vIfpb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c77f52a-26e9-4267-e949-93541ed0cab2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Dataset extracted to /content\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "\n",
        "zip_path = '/content/Dataset.zip'\n",
        "extract_path = '/content'\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "print(\"✅ Dataset extracted to /content\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "21BdTxMKoHt7"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "\n",
        "# Dataset that should go with Alzheimer label\n",
        "very_mild = glob.glob(r'/content/Dataset/Very_Mild_Demented/*')\n",
        "mild = glob.glob(r'/content/Dataset/Mild_Demented/*')\n",
        "moderate = glob.glob(r'/content/Dataset/Moderate_Demented/*')\n",
        "\n",
        "# Dataset without Alzheimer\n",
        "non = glob.glob(r'/content/Dataset/Non_Demented/*')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WqR2uy24oKIx"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "def view_image(directory):\n",
        "    img = mpimg.imread(directory)\n",
        "    plt.imshow(img)\n",
        "    plt.title(directory)\n",
        "    plt.axis('off')\n",
        "    print(f'Image shape: {img.shape}')\n",
        "    return img\n",
        "\n",
        "print('One of the data in Non Alzheimer Folder')\n",
        "print(non[2])\n",
        "view_image(non[2])\n"
      ]
    },
    {
      "source": [
        "import matplotlib.image as mpimg"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "MljIv-LlFwu9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "print(non[2])\n",
        "import matplotlib.image as mpimg # Import the necessary module\n",
        "\n",
        "def view_image(directory):\n",
        "    img = mpimg.imread(directory)\n",
        "    plt.imshow(img)\n",
        "    plt.title(directory)\n",
        "    plt.axis('off')\n",
        "    print(f'Image shape:{img.shape}')\n",
        "    return img\n",
        "\n",
        "print('One of the data in Non Alzheimer Folder')\n",
        "view_image(non[2])"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "PrcaMLUZFsO-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ewuNCNwoTRe"
      },
      "source": [
        "Resizing of data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5e9Z7iW1oM8T"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "# List where arrays shall be stored\n",
        "resized_image_array = []\n",
        "resized_image_array_label = []\n",
        "\n",
        "width = 256\n",
        "height = 256\n",
        "new_size = (width, height)\n",
        "\n",
        "# Iterate over pictures and resize them\n",
        "def resizer(image_directory):\n",
        "    for file in image_directory:\n",
        "        img = Image.open(file)\n",
        "        img = img.resize(new_size)\n",
        "        array_temp = np.array(img)\n",
        "        shape_new = width * height\n",
        "        img_wide = array_temp.reshape(1, shape_new)\n",
        "        resized_image_array.append(img_wide[0])\n",
        "        if image_directory == non:\n",
        "            resized_image_array_label.append(0)\n",
        "        else:\n",
        "            resized_image_array_label.append(1)\n",
        "\n",
        "ALZ = very_mild + mild + moderate\n",
        "resizer(non)\n",
        "resizer(ALZ)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scipy==1.12.0 --force-reinstall\n"
      ],
      "metadata": {
        "id": "f33gC5xXKfG8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JWpdIZlAoacY"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "# Assuming these are defined earlier\n",
        "resized_image_array = []\n",
        "resized_image_array_label = []\n",
        "\n",
        "# Example input: non and ALZ contain lists of image file paths\n",
        "def resizer(image_directory, label):\n",
        "    for file in image_directory:\n",
        "        img = Image.open(file).convert('L')  # Convert to grayscale\n",
        "        img = img.resize((256, 256))         # Resize to 256x256\n",
        "        img_array = np.array(img, dtype=np.float32).flatten()  # Convert and flatten\n",
        "        resized_image_array.append(img_array)\n",
        "        resized_image_array_label.append(label)\n",
        "\n",
        "# Process images for each category\n",
        "resizer(non, 0)   # Label 0 for non-ALZ\n",
        "resizer(ALZ, 1)   # Label 1 for ALZ\n",
        "\n",
        "# Convert to numpy arrays\n",
        "resized_image_array = np.array(resized_image_array, dtype=np.float32)\n",
        "resized_image_array_label = np.array(resized_image_array_label, dtype=np.int32)\n",
        "\n",
        "# Optional: check shapes\n",
        "print(\"Image array shape:\", resized_image_array.shape)\n",
        "print(\"Label array shape:\", resized_image_array_label.shape)\n",
        "\n",
        "# Split the data\n",
        "train_x, test_x, train_y, test_y = train_test_split(\n",
        "    resized_image_array,\n",
        "    resized_image_array_label,\n",
        "    test_size=0.2,\n",
        "    random_state=42  # For reproducibility\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-learn==1.6.1 --force-reinstall\n",
        "\n"
      ],
      "metadata": {
        "id": "aKFkTK1J-ccf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "!pip install numpy==1.26.4 --force-reinstall\n"
      ],
      "metadata": {
        "id": "H7dWwj3X_Y7A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy\n",
        "print(numpy.__version__)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43WYOy8b_vXa",
        "outputId": "fe18c2fa-1bdb-43c0-8a0d-72d984d1af5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.26.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8--fQuQ1JAb1"
      },
      "outputs": [],
      "source": [
        "!pip uninstall -y scikit-image\n",
        "!pip install scikit-image==0.19.3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-qJ1T3O4qnX-"
      },
      "source": [
        "feature extraction using GLCM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "H7p0jixCqkE_"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from skimage.feature import graycomatrix, graycoprops\n",
        "\n",
        "# GLCM parameters\n",
        "distances = [1]\n",
        "angles = [0]\n",
        "properties = ['energy', 'contrast', 'correlation', 'homogeneity', 'ASM']\n",
        "\n",
        "def preprocess_image(image, width, height):\n",
        "    \"\"\"Ensure the image is uint8 and shaped correctly.\"\"\"\n",
        "    image = image.reshape((width, height))  # reshape if needed\n",
        "    if image.dtype != np.uint8:\n",
        "        if image.max() <= 1.0:\n",
        "            image = (image * 255).astype(np.uint8)\n",
        "        else:\n",
        "            image = image.astype(np.uint8)\n",
        "    return image\n",
        "\n",
        "def extract_glcm_features(images, width, height):\n",
        "    features_list = []\n",
        "    for img in images:\n",
        "        img = preprocess_image(img, width, height)\n",
        "        glcm = graycomatrix(img, distances=distances, angles=angles, levels=256, symmetric=True, normed=True)\n",
        "        features = [graycoprops(glcm, prop)[0][0] for prop in properties]\n",
        "        features_list.append(features)\n",
        "    return features_list\n",
        "\n",
        "# Set correct image dimensions\n",
        "width, height = 256, 256  # update to match your actual resized image size\n",
        "\n",
        "# Apply feature extraction\n",
        "train_glcm_features = extract_glcm_features(train_x, width, height)\n",
        "test_glcm_features = extract_glcm_features(test_x, width, height)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y scipy\n",
        "!pip install scipy --upgrade --force-reinstall\n"
      ],
      "metadata": {
        "id": "SkKi2RIoNgNw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CboOEM74ij-_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "956014cb-c3eb-44e7-e3c7-9b3c64fed379"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.62109375\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# create an SVM classifier with a linear kernel\n",
        "clf = SVC(kernel='linear')\n",
        "\n",
        "# fit the classifier to the training data\n",
        "clf.fit(train_glcm_features, train_y)\n",
        "\n",
        "# make predictions on the test data\n",
        "y_pred = clf.predict(test_glcm_features)\n",
        "\n",
        "# compute the accuracy of the classifier\n",
        "accuracy = accuracy_score(test_y, y_pred)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TLUlIaUOdYlD"
      },
      "outputs": [],
      "source": [
        "# import numpy as np\n",
        "# from PIL import Image\n",
        "# from skimage.feature import greycomatrix, greycoprops\n",
        "# from sklearn.svm import SVC\n",
        "# from sklearn.metrics import accuracy_score\n",
        "\n",
        "# # Load and preprocess the new image\n",
        "# def preprocess_new_image(img_path, new_size=(256, 256)):\n",
        "#     img = Image.open(img_path)\n",
        "#     img = img.resize(new_size)\n",
        "#     img_array = np.array(img)\n",
        "#     return img_array\n",
        "\n",
        "# # Extract GLCM features from the image\n",
        "# # def extract_glcm_features(img_array, distances=[1], angles=[0], properties=['energy', 'contrast', 'correlation', 'homogeneity', 'ASM']):\n",
        "# #     glcm = greycomatrix(img_array, distances=distances, angles=angles, levels=256, symmetric=True, normed=True)\n",
        "# #     features = [greycoprops(glcm, prop)[0][0] for prop in properties]\n",
        "# #     return features\n",
        "\n",
        "# def extract_glcm_features(img_array, distances=[1], angles=[0], properties=['energy', 'contrast', 'correlation', 'homogeneity', 'ASM']):\n",
        "#     glcm = greycomatrix(img_array, distances=distances, angles=angles, levels=256, symmetric=True, normed=True)\n",
        "#     features = [greycoprops(glcm, prop)[0][0] for prop in properties]\n",
        "#     return features\n",
        "\n",
        "# # Function to predict if the person has dementia\n",
        "# def predict_dementia(img_path, clf, new_size=(256, 256)):\n",
        "#     img_array = preprocess_new_image(img_path, new_size)\n",
        "#     features = extract_glcm_features(img_array)\n",
        "#     prediction = clf.predict([features])\n",
        "#     if prediction[0] == 1:\n",
        "#         return 'Dementia'\n",
        "#     else:\n",
        "#         return 'No Dementia'\n",
        "# img_path = '/content/dementedeimage.jpeg' # Replace with the path to your new MRI image\n",
        "# result = predict_dementia(img_path, clf)\n",
        "# print(f'The prediction for the MRI image is: {result}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y scikit-image\n",
        "!pip install scikit-image==0.21.0\n"
      ],
      "metadata": {
        "id": "cRlsjmdpVMi9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from skimage.feature import graycomatrix\n",
        "from skimage.color import rgb2gray\n",
        "from PIL import Image\n",
        "\n",
        "# Load and preprocess image\n",
        "img = Image.open(\"/content/Dataset/Non_Demented/non_577.jpg\").convert('L')\n",
        "gray_img = np.array(img)\n",
        "\n",
        "# Compute GLCM\n",
        "glcm = graycomatrix(gray_img, distances=[1], angles=[0], levels=256, symmetric=True, normed=True)\n",
        "glcm = glcm[:, :, 0, 0]  # Extract 2D matrix\n",
        "\n",
        "# --- Manually compute texture features ---\n",
        "# 1. Contrast\n",
        "i, j = np.indices(glcm.shape)\n",
        "contrast = np.sum(glcm * (i - j) ** 2)\n",
        "\n",
        "# 2. Energy\n",
        "energy = np.sum(glcm ** 2)\n",
        "\n",
        "# 3. Homogeneity\n",
        "homogeneity = np.sum(glcm / (1.0 + np.abs(i - j)))\n",
        "\n",
        "# 4. ASM (Angular Second Moment)\n",
        "asm = energy  # same as energy\n",
        "\n",
        "# 5. Dissimilarity\n",
        "dissimilarity = np.sum(glcm * np.abs(i - j))\n",
        "\n",
        "# Output\n",
        "print(f\"Contrast: {contrast:.4f}\")\n",
        "print(f\"Energy: {energy:.4f}\")\n",
        "print(f\"Homogeneity: {homogeneity:.4f}\")\n",
        "print(f\"Dissimilarity: {dissimilarity:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IBfiV62zVqrm",
        "outputId": "45609141-dc6f-42bb-9b2a-e353654a241f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Contrast: 264.1829\n",
            "Energy: 0.2065\n",
            "Homogeneity: 0.5587\n",
            "Dissimilarity: 8.2811\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h4pnDoyISKPG"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "from skimage.feature import graycomatrix, greycoprops\n",
        "from skimage.color import rgb2gray\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SlETKa7eSMjv"
      },
      "outputs": [],
      "source": [
        "def preprocess_new_image(img_path, new_size=(256, 256)):\n",
        "    img = Image.open(img_path).convert('RGB')      # Ensure it's RGB\n",
        "    img = img.resize(new_size)\n",
        "    img_array = np.array(img)\n",
        "    gray_image = rgb2gray(img_array)               # Convert to grayscale\n",
        "    gray_image = (gray_image * 255).astype(np.uint8)  # Convert to uint8 (0-255)\n",
        "    return gray_image\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BTOEDWjZSRy6"
      },
      "outputs": [],
      "source": [
        "def extract_glcm_features(img_array, distances=[1], angles=[0], properties=['energy', 'contrast', 'correlation', 'homogeneity', 'ASM']):\n",
        "    glcm = graycomatrix(img_array, distances=distances, angles=angles, levels=256, symmetric=True, normed=True)\n",
        "    features = [greycoprops(glcm, prop)[0][0] for prop in properties]\n",
        "    return features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4G-JikohSVMG"
      },
      "outputs": [],
      "source": [
        "def predict_dementia(img_path, clf, new_size=(256, 256)):\n",
        "    img_array = preprocess_new_image(img_path, new_size)\n",
        "    features = extract_glcm_features(img_array)\n",
        "    prediction = clf.predict([features])\n",
        "    return 'Dementia' if prediction[0] == 1 else 'No Dementia'\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ],
      "metadata": {
        "id": "8H6pfQtsODbQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SJgrkBkdjjAQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uq2tbLWnSY9A"
      },
      "outputs": [],
      "source": [
        "img_path = 'dementedimage.jpeg'  # No need for /content/ if it's uploaded via Colab\n",
        "result = predict_dementia(img_path, clf);\n",
        "print(f'The prediction for the MRI image is: {result}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j3JNN6tOqrqf"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# create a RF classifier with 100 trees\n",
        "clf = RandomForestClassifier(n_estimators=100)\n",
        "\n",
        "# fit the classifier to the training data\n",
        "clf.fit(train_glcm_features, train_y)\n",
        "\n",
        "# make predictions on the test data\n",
        "y_pred = clf.predict(test_glcm_features)\n",
        "\n",
        "# compute the accuracy of the classifier\n",
        "accuracy = accuracy_score(test_y, y_pred)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uoXbshQhrcRu"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "clf = RandomForestClassifier()\n",
        "# perform k-fold cross-validation (here k=5)\n",
        "scores = cross_val_score(clf, train_glcm_features, train_y, cv=5)\n",
        "\n",
        "# print the accuracy for each fold\n",
        "print(\"Cross-validation scores:\", scores)\n",
        "\n",
        "# compute the mean and standard deviation of the accuracy across all folds\n",
        "mean_accuracy = scores.mean()\n",
        "std_accuracy = scores.std()\n",
        "\n",
        "print(\"Mean accuracy:\", mean_accuracy)\n",
        "print(\"Standard deviation:\", std_accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMj3RStXrPrw"
      },
      "source": [
        "feature extraction using Gabor Filter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qozqL-0mqxcx"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "# Define the parameters for the Gabor filter\n",
        "ksize = 31  # size of the filter kernel\n",
        "sigma = 4  # standard deviation of the Gaussian function used in the filter\n",
        "theta = 0  # orientation of the filter\n",
        "lambd = 10  # wavelength of the sinusoidal factor in the filter\n",
        "gamma = 0.5  # spatial aspect ratio of the filter\n",
        "\n",
        "# Create the Gabor filter\n",
        "kernel = cv2.getGaborKernel((ksize, ksize), sigma, theta, lambd, gamma, 0, ktype=cv2.CV_32F)\n",
        "\n",
        "# Apply the Gabor filter to each image\n",
        "gabor_features_train = []\n",
        "for img in train_x:\n",
        "    # Convert the image from a 1D array to a 2D array\n",
        "    img_2d = np.reshape(img, (height, width)).astype(np.float32)\n",
        "    # Apply the Gabor filter to the image\n",
        "    filtered_img = cv2.filter2D(img_2d, cv2.CV_8UC3, kernel)\n",
        "    # Convert the filtered image back to a 1D array and add it to the feature list\n",
        "    gabor_features_train.append(np.ravel(filtered_img))\n",
        "\n",
        "gabor_features_test = []\n",
        "for img in test_x:\n",
        "    # Convert the image from a 1D array to a 2D array\n",
        "    img_2d = np.reshape(img, (height, width)).astype(np.float32)\n",
        "    # Apply the Gabor filter to the image\n",
        "    filtered_img = cv2.filter2D(img_2d, cv2.CV_8UC3, kernel)\n",
        "    # Convert the filtered image back to a 1D array and add it to the feature list\n",
        "    gabor_features_test.append(np.ravel(filtered_img))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XD-G2T3-MzGq"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load image\n",
        "img = cv2.imread('/content/Dataset/Non_Demented/non.jpg', 0)\n",
        "\n",
        "# Define parameters for Gabor filter\n",
        "ksize = 31\n",
        "sigma = 5\n",
        "theta = 0\n",
        "lamda = 10\n",
        "gamma = 0.5\n",
        "phi = 0\n",
        "\n",
        "# Create Gabor filter\n",
        "kernel = cv2.getGaborKernel((ksize, ksize), sigma, theta, lamda, gamma, phi, ktype=cv2.CV_32F)\n",
        "\n",
        "# Apply Gabor filter to image\n",
        "filtered_img = cv2.filter2D(img, cv2.CV_8UC3, kernel)\n",
        "\n",
        "# Display original image and filtered image side by side\n",
        "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
        "ax[0].imshow(img, cmap='gray')\n",
        "ax[0].set_title('Original Image')\n",
        "ax[0].axis('off')\n",
        "ax[1].imshow(filtered_img, cmap='gray')\n",
        "ax[1].set_title('Filtered Image')\n",
        "ax[1].axis('off')\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ATGsqh2FrTzr"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# create a RF classifier with 100 trees\n",
        "clf = RandomForestClassifier(n_estimators=100)\n",
        "\n",
        "# fit the classifier to the training data\n",
        "clf.fit(gabor_features_train, train_y)\n",
        "\n",
        "# make predictions on the test data\n",
        "y_pred = clf.predict(gabor_features_test)\n",
        "\n",
        "# compute the accuracy of the classifier\n",
        "accuracy = accuracy_score(test_y, y_pred)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LK95T3zwtx5b"
      },
      "outputs": [],
      "source": [
        "# Add Linear Regression model (Logistic Regression)\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Create a logistic regression classifier\n",
        "clf_lr = LogisticRegression(max_iter=1000)\n",
        "\n",
        "# Fit the classifier to the training data\n",
        "clf_lr.fit(train_glcm_features, train_y)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred_lr = clf_lr.predict(test_glcm_features)\n",
        "\n",
        "# Compute the accuracy of the classifier\n",
        "accuracy_lr = accuracy_score(test_y, y_pred_lr)\n",
        "\n",
        "# Print the accuracy\n",
        "print(\"Logistic Regression Accuracy:\", accuracy_lr)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5oRqHM-rt4Mr"
      },
      "outputs": [],
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# # Accuracies of the models\n",
        "# accuracies = {\n",
        "#     'SVM': accuracy,\n",
        "#     'Random Forest': accuracy_r,\n",
        "#     'Logistic Regression': accuracy_lr\n",
        "# }\n",
        "\n",
        "# # Plotting the accuracies\n",
        "# plt.figure(figsize=(10, 5))\n",
        "# plt.bar(accuracies.keys(), accuracies.values(), color=['blue', 'green', 'red'])\n",
        "# plt.xlabel('Model')\n",
        "# plt.ylabel('Accuracy')\n",
        "# plt.title('Accuracies of Different Models')\n",
        "# plt.ylim(0, 1)  # Accuracy ranges from 0 to 1\n",
        "# plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1gIA-plfrrQL"
      },
      "source": [
        "mean square error of RF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3mjTBpkmKZHm"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}